---
layout: page
title: research 
permalink: /projects/
description: 
nav: true
nav_order: 2
display_categories: []
horizontal: false
---
### Broad Research Vision
 We stand at the dawn of a technological and scientific revolution, with AI as its center. Despite its potential, our understanding of advanced AI systems is still very limited, as revealed by the following fact: the human brain, the inspiration behind modern neural networks, operates on a mere 12 watts, in stark contrast to the megawatts consumed by advanced neural networks. Therefore, state-of-the-art neural networks burn millions of times more power and data than a biological brain while coming short of simple reasoning and common sense tasks. Perhaps more importantly, the collective carbon footprint of AI has been increasing exponentially, rendering it unsustainable in the long term. This observation points to an urgent need for a deeper, fundamental understanding of neural networks to build models that are not just efficient but also sustainably intelligent. As a doctoral researcher, my broad research vision is to move towards such a fundamental understanding of neural networks to pave the way for their wider adoption, including their biomedical applications.

### Research projects
I'm very open to collaboration. Don't hesitate to contact me if you want to collaborate on any of the topics I work on. If you're a masters student looking for interesting projects to do during your studies or for your thesis, here is a list of available projects for MSc theses. Please send me an email with your CV and transcripts if you're interested! 

##### Genomics:
- [Learning metagenome graphs by GNNs](https://drive.google.com/file/d/1Awqp4zKp2VcOGlz0NvlJ8O9JNL10UGJG/view?usp=sharing), co-advised by Manuel Burger
- "Foundational sequence representations for single cell sequencing", co-supervised by Stefan Stark

##### Neural Network Theory:
- [Can a transformer learn sequence alignment?](https://docs.google.com/document/d/1V1DDJCjALvgSsY73nKxzAxvE33LkIu0VymkD88ckJHg/edit?usp=sharing)
- [Replacing normalization with initialization](https://drive.google.com/file/d/1jKK4znnd1xzHgMdeHjG3ZSpzslnqTN3I/view?usp=sharing)
- [Mystery of activation in neural nets](https://drive.google.com/file/d/1jw2dKeubR6BXUMAzJO5FGTJAWzMQlxN2/view?usp=share_link)
- Understanding pretraining speed in transformers.
- [Zero-shot neural architecture search](https://drive.google.com/file/d/13mLc10A9mCnbREJCS5qiP7z09WNxLakh/view?usp=sharing)

##### Medical 
- [Doctor in the loop](https://docs.google.com/document/d/1s-I7TrJAXPvVP7LQfamZUMm3VpEigVtRyDYrjorfZJU/edit) (Active Learning + Medical), co-advised by Hugo YÃ©che
